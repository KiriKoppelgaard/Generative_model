{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A generative model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we did was to download Hans Christian Andersen fairytales from Gutenberg.\n",
    "\n",
    "What do we need to look out for when cleaning the data:\n",
    "\n",
    "- Punctuation \n",
    "- The file consist of multiple stories --> need to divide it into different parts (might be possible to split after headers written in capital letters)\n",
    "- Capital letters as headers, might want to delete these\n",
    "- Change everything to lower caser \n",
    "- Illustrations, delete them, written as ([Illustration: _His limbs were numbed, his beautiful eyes were closing.-])\n",
    "- British spelling\n",
    "- Weird names \n",
    "\n",
    "\n",
    "We have to decide the input sequences, which is the number of words that the model will train on. This is also the number of words which will be used as the seed text, when using the model to actually generate new sequences. \n",
    "\n",
    "In the tutorial 50 words are suggested. We will start with that and then in the fifth lesson we might try to only use sequences inside sentences, though this will minimize the amount of training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation on the following two coding blocks:\n",
    "https://www.pythonforbeginners.com/files/reading-and-writing-files-in-python\n",
    "- How to open text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to load the text into memory\n",
    "def load_text(filename): #we decide that the function is called load_text\n",
    "    file = open(filename, 'r') #open() is used to open/loading a filename, the mode indicates how it should be opened, r = read, w = writing, a = appending \n",
    "    text = file.read() # read the file and assign it to the variable text\n",
    "    file.close() #close the file again\n",
    "    return text #ends function and specify what output the want, we want text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the documents\n",
    "#text_1 = 'Data/gutenberg_hc_1.txt'\n",
    "#text_2 = 'Data/gutenberg_hc_1.txt'\n",
    "\n",
    "#doc_1 = load_text(text_1)\n",
    "#doc_2 = load_text(text_2)\n",
    "\n",
    "#but we actually want to concatenate the two files, so we will use another function\n",
    "\n",
    "#concatenate text files\n",
    "filenames = ['Data/gutenberg_hc_1.txt', 'Data/gutenberg_hc_1.txt'] #specify the filenames that we want to concatenate\n",
    "\n",
    "with open('Data/fairytales.txt', 'w') as outfile: #specify where the file should be saved and what it should be called (if a file with that name already exists, it will be overwritten, 'w' is used to edit and write new information to a file \n",
    "    for text in filenames: #for all the text in the filenames, do the following...\n",
    "        with open(text) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whats up with this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to look at in lecture 5 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input sequences\n",
    "\n",
    "\n",
    "We could process the data so that the model only ever deals with self-contained sentences and pad or truncate the text to meet this requirement for each input sequence. You could explore this as an extension to this tutorial.\n",
    "- Instead, to keep the example brief, we will let all of the text flow together and train the model to predict the next word across sentences, paragraphs, and even books or chapters in the text."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp_the_project]",
   "language": "python",
   "name": "conda-env-nlp_the_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
