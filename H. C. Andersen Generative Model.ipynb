{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data (lesson 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting of by downloading data and looking at the data, which we need to clean. We observe following\n",
    "- Illustration texts\n",
    "- The text file contain multiple stories, these should be split into multiple files in order for the model to know there is groupings\n",
    "- The file contains a number of punctuations (,;.* etc.), which are irrelevant for the model\n",
    "- Capital letters as headers\n",
    "- Weird names: Kay, Gerda\n",
    "- British spelling: e.g. \"rose-coloured\"\n",
    "\n",
    "The input sequences are at first at 50 across sentences, chapters and stories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to load documents into memory\n",
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r') #loading an existing file\n",
    "\ttext = file.read() #opening the file and assigning it to the variable text\n",
    "\tfile.close() #close the file\n",
    "\treturn text #output = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate text files\n",
    "filenames = ['Data/pg17860.txt', 'Data/32571-0.txt']\n",
    "\n",
    "with open('Data/adventures.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿THE SNOW QUEEN\n",
      "\n",
      "A TALE IN SEVEN STORIES\n",
      "\n",
      "FIRST STORY\n",
      "\n",
      "WHICH DEALS WITH A MIRROR AND ITS FRAGMENTS\n",
      "\n",
      "[Illustration: _One day he was in a high state of delight because he had\n",
      "invented a mirror with this peculiarity, that every good and pretty\n",
      "thing reflected in it shrank away to almost nothing._]\n",
      "\n",
      "Now we are about to begin, and you must attend; and when we get to the\n",
      "end of the story, you will know more than you do now about a very wicked\n",
      "hobgoblin. He was one of the worst kind; in fact he was a real demon.\n",
      "One day he was in a high state of delight because he had invented a\n",
      "mirror with this peculiarity, that every good and pretty thing reflected\n",
      "in it shrank away to almost nothing. On the other hand, every bad and\n",
      "good-for-nothing thing stood out and looked its worst. The most\n",
      "beautiful landscapes reflected in it looked like boiled spinach, and the\n",
      "best people became hideous, or else they were upside down and had no\n",
      "bodies. Their faces were distorted beyond recognition, and if they had\n"
     ]
    }
   ],
   "source": [
    "# load document\n",
    "in_filename = 'Data/adventures.txt'#specifying the filename of the data we wish to load\n",
    "doc = load_doc(in_filename) #loading the file\n",
    "print(doc[:1000]) #printing the first 200 characters of the loading document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:\n",
    "During this lesson, we managed to get Jupyter Notebook running, creating a new codebook chunk. This took longer than expected, which in the end due to timepressure left unresolved problems, such as the unconcatenated files. Signe's computer said a wierd noise and began to smoke, this also influenced the process. We have decided to work on the code silmuntanously apart, since this will maximize the individual learning. We collaborate orally and help fixing eachothers problems. This procedure suited both of us. Before next lesson we would like to have solved the problem with concatenating the files. We will look at this individually. In order to share code, we will upload the code file to a collaborative folder in GitHub. This will also allow us to exchange the solution to our current problem with concatenating. We assess that we have obtained the learning goal of getting acquainted with the corpus, which will be used to train the model. Though it might be a good idea to gain more data. For next we would like to organise the lesson better. It took quite a while planning time slots for future lessons and getting the process started as we had problems with getting Jupyter Notebook running. On the other it makes sense that we had a longer introductory phase this lesson. Also we would like to reorder the outline of the lesson, so we start out with discussing the extra literature instead of ending off with it. \n",
    "\n",
    "Key connections between lecture and project:\n",
    "- Deep learning is a type of machine learning, which employs a neural network with hidden units\n",
    "- The reason for the popularity of deep learning is that it is proven to be very efficient and work very well compared to other machine learning techniques\n",
    "- Deep learning is widely employed in our everyday life\n",
    "- How do we represent meaning? This is solved in natural language processing by word-vectors, which we will also use in pur project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data (lesson 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lesson 1, we observed several potential issues in the data, which we need to remove from the data. This is done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿THE SNOW QUEEN\n",
      "\n",
      "A TALE IN SEVEN STORIES\n",
      "\n",
      "FIRST STORY\n",
      "\n",
      "WHICH DEALS WITH A MIRROR AND ITS FRAGMENTS\n",
      "\n",
      "\n",
      "\n",
      "At home in the prince's palace, when at night the others were\n",
      "asleep, she used to go out on to the marble steps; it cooled her\n",
      "burning feet to stand in the cold sea-water, and at such times she used\n",
      "to think of those she had left in the deep.\n",
      "\n",
      "One night her sisters came arm in arm; they sang so sorrowfully as they\n",
      "swam on the water that she beckoned to them, and they recognised her,\n",
      "and told her how she had grieved them all. After that they visited her\n",
      "every night, and one night she saw, a long way out, her old grandmother\n",
      "(who for many years had not been above the water), and the Merman King\n",
      "with his crown on his head; they stretched out their hands towards her,\n",
      "but did not venture so close to land as her sisters.\n",
      "\n",
      "Day by day she became dearer to the prince; he loved her as one loves a\n",
      "good sweet child, but it never entered his head to make her his queen;\n",
      "yet unless she became his w\n"
     ]
    }
   ],
   "source": [
    "#removing illustration descriptions\n",
    "doc = re.sub(r'\\[[^)]*\\]', '', doc) #using re.sub function and regular expressions \n",
    "#( - an opening round bracket \n",
    "#[^()]* - zero or more characters other than those defined in the negated character class/POSIX bracket expression, that is, any chars other than [ and ]\n",
    "#\\) - a closing bracket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing special characters, since one of the deliminators \n",
    "#deliminators \n",
    "deliminators = c(THE FIR TREE, LITTLE TUK, THE UGLY DUCKLING, 'LITTLE IDA'S FLOWERS', 'THE STEADFAST TIN SOLDIER      67\n",
    "          LITTLE THUMBELINA              77\n",
    "          SUNSHINE STORIES              101\n",
    "          THE DARNING-NEEDLE            109\n",
    "          THE LITTLE MATCH GIRL         117\n",
    "          THE LOVING PAIR               124\n",
    "          THE LEAPING MATCH             129\n",
    "          THE HAPPY FAMILY              134\n",
    "          THE GREENIES                  141\n",
    "          OLE-LUK-OIE, THE DREAM GOD    145\n",
    "          THE MONEY BOX                 169\n",
    "          ELDER-TREE MOTHER             174\n",
    "          THE SNOW QUEEN                192\n",
    "          THE ROSES AND THE SPARROWS    253\n",
    "          THE OLD HOUSE                 273\n",
    "          THE CONCEITED APPLE BRANCH    290\n",
    "          NOTES                         299\n",
    "        \n",
    "\n",
    "#splitting the file into strings consisting of one adventure\n",
    "doc = doc.split ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# replace '--' with a space ' '\n",
    "\tdoc = doc.replace('--', ' ')\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# make lower case\n",
    "\ttokens = [word.lower() for word in tokens]\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to be consider to advance the model: \n",
    "\n",
    "- We could process the data so that the model only ever deals with self-contained sentences and pad or truncate the text to meet this requirement for each input sequence. You could explore this as an extension to this tutorial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ldm)",
   "language": "python",
   "name": "ldm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
